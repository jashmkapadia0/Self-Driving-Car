import torch
import cv2
import numpy as np
from ultralytics import YOLO
import time

# Constants for optimization - Modified for better performance
CONF_THRESHOLD = 0.5     # Increased to reduce false positives
IOU_THRESHOLD = 0.5      # Increased for faster NMS
IMG_SIZE = 416           # Reduced from 640 for faster processing
FRAME_SKIP = 3          # Increased frame skip
DANGER_THRESHOLD = 0.6
MAX_BATCH_SIZE = 1      # Limit batch size

def gstreamer_pipeline(
    sensor_id=0,
    capture_width=640,   # Reduced capture resolution
    capture_height=480,  # Reduced capture resolution
    display_width=640,   # Reduced display resolution
    display_height=480,  # Reduced display resolution
    framerate=30,
    flip_method=0
):
    return (
        f"nvarguscamerasrc sensor-id={sensor_id} ! "
        f"video/x-raw(memory:NVMM), width=(int){capture_width}, "
        f"height=(int){capture_height}, format=(string)NV12, "
        f"framerate=(fraction){framerate}/1 ! nvvidconv flip-method={flip_method} ! "
        f"video/x-raw, width=(int){display_width}, height=(int){display_height}, "
        f"format=(string)BGRx ! videoconvert ! video/x-raw, format=(string)BGR ! appsink drop=1"  # Added drop=1
    )

class ObjectDetector:
    def __init__(self):
        # Model initialization with optimizations
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        try:
            self.model = YOLO('yolov5n.pt')  # Using smallest model
            self.model.conf = CONF_THRESHOLD
            self.model.iou = IOU_THRESHOLD
            if torch.cuda.is_available():
                self.model.half()  # FP16 inference
            print(f"Model loaded on {self.device}")
        except Exception as e:
            print(f"Error loading model: {e}")
            raise

        # Initialize camera with optimized settings
        try:
            self.cap = cv2.VideoCapture(gstreamer_pipeline(), cv2.CAP_GSTREAMER)
            if not self.cap.isOpened():
                raise RuntimeError("Failed to open CSI camera!")
        except Exception as e:
            print(f"CSI camera error: {e}")
            print("Falling back to USB camera...")
            self.cap = cv2.VideoCapture(0)
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            if not self.cap.isOpened():
                raise RuntimeError("No camera available!")

        self.frame_count = 0
        self.fps_start_time = time.time()
        self.moving_avg_fps = []

    def process_frame(self):
        ret, frame = self.cap.read()
        if not ret:
            return False, None

        self.frame_count += 1
        if self.frame_count % FRAME_SKIP != 0:
            return True, frame  # Return original frame without processing

        # Optimize frame preprocessing
        frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))
        
        # Model inference with optimizations
        results = self.model(frame, 
                           augment=False,  # Disabled augmentation
                           half=True if torch.cuda.is_available() else False,  # FP16
                           max_det=10)     # Limit maximum detections
        
        if results and len(results) > 0:
            result = results[0]
            boxes = result.boxes

            # Simplified detection processing
            if len(boxes) > 0:
                # Get only the most dangerous object
                most_dangerous = None
                max_danger = 0
                
                for box in boxes:
                    label = result.names[int(box.cls)]
                    if label in ['person', 'car', 'truck', 'bus']:  # Only process critical objects
                        danger_score = self.calculate_danger_score(box)
                        if danger_score > max_danger:
                            max_danger = danger_score
                            most_dangerous = (label, float(box.conf), danger_score)

                if most_dangerous:
                    label, conf, danger = most_dangerous
                    if danger > DANGER_THRESHOLD:
                        print(f"!! WARNING !! {label} (Danger: {danger:.2f})")

            # Quick visualization
            annotated_frame = result.plot(conf=False)  # Disable confidence display for speed
            
            # Calculate FPS
            if time.time() - self.fps_start_time > 1.0:
                fps = self.frame_count / (time.time() - self.fps_start_time)
                self.frame_count = 0
                self.fps_start_time = time.time()
                cv2.putText(annotated_frame, f"FPS: {fps:.1f}", (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

            return True, annotated_frame
        
        return True, frame

    def calculate_danger_score(self, box):
        """Simplified danger score calculation"""
        x1, y1, x2, y2 = map(float, box.xyxy[0])
        box_area = (x2 - x1) * (y2 - y1)
        return box_area / (IMG_SIZE * IMG_SIZE)

    def run(self):
        try:
            while True:
                success, frame = self.process_frame()
                if not success:
                    break
                
                if frame is not None:
                    cv2.imshow("Jetson Nano Detection", frame)
                
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

        finally:
            self.cap.release()
            cv2.destroyAllWindows()

if __name__ == "__main__":
    try:
        detector = ObjectDetector()
        detector.run()
    except Exception as e:
        print(f"Fatal error: {e}")
